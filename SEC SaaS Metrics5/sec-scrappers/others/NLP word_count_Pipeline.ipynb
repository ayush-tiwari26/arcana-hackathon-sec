{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5SrMQ1ng1XL0"},"outputs":[],"source":["# importing the required libraries\n","import pandas as pd\n","import numpy as np\n","import textwrap\n","import os\n","import json\n","from tqdm import tqdm\n","import nltk\n","import regex as re\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtZvTvfo1XL1"},"outputs":[],"source":["os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ea1YCmCf1XL2"},"outputs":[],"source":["# enter the base_path\n","base_path = \"\"\n","store_path = base_path + \"/\" +\"10_K_word_count/\"\n","files_path = base_path + \"/\" +\"10_K/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JEfoEgRO1XL2","outputId":"8267dcf9-e7a9-4e60-f16b-223d2c1fa15b"},"outputs":[{"data":{"text/plain":["174"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# getting file names\n","files = os.listdir(files_path)\n","len(files)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yI24CWaV1XL3"},"outputs":[],"source":["# testing one file\n","fp = open(files_path+files[0], 'r')\n","df = json.load(fp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yW9fAcD61XL3"},"outputs":[],"source":["# get stopwords list from nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop_words = set(stopwords.words('english'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYnvTHjV1XL3"},"outputs":[],"source":["text = df['item_7'] +df['item_7A']\n","\n","def give_word_count_dict(text):\n","    # clean text using regex\n","    text = re.sub(r'[^\\w\\s]','',text)\n","    # remove stop words\n","    text = ' '.join([word for word in text.split() if word not in stopwords])\n","\n","    # split text into words\n","    words = text.split()\n","    # create a dictionary with word as key and its count as value\n","    word_count_dict = {}\n","    for word in words:\n","        if word in word_count_dict:\n","            word_count_dict[word] += 1\n","        else:\n","            word_count_dict[word] = 1\n","    return word_count_dict\n","\n","\n","word_count_dict = give_word_count_dict(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VaW4cJAX1XL3"},"outputs":[],"source":["def give_bigram_and_trigram_dict(text):\n","    # clean text using regex\n","    text = re.sub(r'[^\\w\\s]','',text)\n","    # remove stop words\n","    text = ' '.join([word for word in text.split() if word not in stopwords])\n","    # now get ngram counts in the text using nltk\n","    bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(text.split())\n","    trigram_finder = nltk.collocations.TrigramCollocationFinder.from_words(text.split())\n","    # get bigram and trigram counts\n","    bigram_counts = bigram_finder.ngram_fd.items()\n","    trigram_counts = trigram_finder.ngram_fd.items()\n","    # create a dictionary with bigram and trigram as key and its count as value\n","    bigram_dict = {}\n","    trigram_dict = {}\n","    for bigram, count in bigram_counts:\n","        bigram_dict[bigram[0]+ \" \" +bigram[1]] = count\n","    for trigram, count in trigram_counts:\n","        trigram_dict[trigram[0]+ \" \" +trigram[1]] = count\n","    return bigram_dict, trigram_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCJYdYZu1XL4","outputId":"b46307e7-68fe-4a8a-8d4c-777ef224b137"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bigram</th>\n","      <th>bigram_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>December 31</td>\n","      <td>78</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ended December</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The Company</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>year ended</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The Companys</td>\n","      <td>37</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           bigram  bigram_count\n","0     December 31            78\n","1  ended December            61\n","2     The Company            58\n","3      year ended            53\n","4    The Companys            37"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# get the bigram and trigram counts\n","bigram_dict, trigram_dict = give_bigram_and_trigram_dict(text)\n","\n","# sort both the dicts on th basis of their values\n","bigram_dict = dict(sorted(bigram_dict.items(), key=lambda x: x[1], reverse=True))\n","trigram_dict = dict(sorted(trigram_dict.items(), key=lambda x: x[1], reverse=True))\n","\n","\n","# save both of these in a csv file\n","d2 = pd.DataFrame(bigram_dict.items(),columns=['bigram', 'bigram_count'])\n","d3 = pd.DataFrame(trigram_dict.items(), columns=['trigram', 'trigram_count'])\n","d2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jzlrp4kX1XL4","outputId":"2fefef75-8c53-451d-9069-ee0d44881959"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>trigram</th>\n","      <th>trigram_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ended December</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>year ended</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>compared year</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>foreign exchange</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>million year</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            trigram  trigram_count\n","0    ended December             61\n","1        year ended             53\n","2     compared year             12\n","3  foreign exchange             10\n","4      million year             10"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["d3.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97Ex8q2W1XL4","outputId":"05acec4d-b37e-4632-97eb-cba93979ac33"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The</td>\n","      <td>181</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>million</td>\n","      <td>128</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Companys</td>\n","      <td>124</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Company</td>\n","      <td>121</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>year</td>\n","      <td>95</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       word  count\n","0       The    181\n","1   million    128\n","2  Companys    124\n","3   Company    121\n","4      year     95"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# sort the word count dictionary in descending order\n","sorted_word_count_dict = sorted(word_count_dict.items(), key=lambda x: x[1], reverse=True)\n","# save sorted_word_count_dict to a csv file\n","d = pd.DataFrame(sorted_word_count_dict, columns=['word', 'count'])\n","d.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTmWiaty1XL5"},"outputs":[],"source":["# provided a text input, this function gives all three word count, bigram_count and trigram_count\n","def give_all_three_occurences(text):\n","    \n","    # clean text using regex\n","    text = re.sub(r'[^\\w\\s]','',text)\n","    # remove stop words\n","    text = ' '.join([word for word in text.split() if word not in stop_words])\n","    # now get ngram counts in the text using nltk\n","    bigram_finder = nltk.collocations.BigramCollocationFinder.from_words(text.split())\n","    trigram_finder = nltk.collocations.TrigramCollocationFinder.from_words(text.split())\n","    # get bigram and trigram counts\n","    bigram_counts = bigram_finder.ngram_fd.items()\n","    trigram_counts = trigram_finder.ngram_fd.items()\n","    # create a dictionary with bigram and trigram as key and its count as value\n","    bigram_dict = {}\n","    trigram_dict = {}\n","    for bigram, count in bigram_counts:\n","        bigram_dict[bigram[0]+ \" \" +bigram[1]] = count\n","    for trigram, count in trigram_counts:\n","        trigram_dict[trigram[0]+ \" \" +trigram[1]] = count\n","\n","    # split text into words\n","    words = text.split()\n","    # create a dictionary with word as key and its count as value\n","    word_count_dict = {}\n","    for word in words:\n","        if word in word_count_dict:\n","            word_count_dict[word] += 1\n","        else:\n","            word_count_dict[word] = 1\n","\n","    # sort both the dicts on th basis of their values\n","    bigram_dict = dict(sorted(bigram_dict.items(), key=lambda x: x[1], reverse=True))\n","    trigram_dict = dict(sorted(trigram_dict.items(),key=lambda x: x[1], reverse=True))\n","\n","    # sort the word count dictionary in descending order\n","    sorted_word_count_dict = sorted(word_count_dict.items(), key=lambda x: x[1], reverse=True)\n","    \n","    d = pd.DataFrame(sorted_word_count_dict, columns=['word', 'count'])\n","    d2 = pd.DataFrame(bigram_dict.items(),columns=['bigram', 'bigram_count'])\n","    d3 = pd.DataFrame(trigram_dict.items(), columns=['trigram', 'trigram_count'])\n","\n","    return d,d2,d3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7QYBx0cF1XL5","outputId":"5dbe13b5-fafd-4def-f5b9-176fc60cf1a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 174/174 [00:31<00:00,  5.51it/s]\n"]}],"source":["# this list to check some of badly scraped files for correction\n","files_that_dont_have_item_7A = []\n","for i in tqdm(files,position=0, leave = True):\n","    try:\n","        fp = open(files_path+i, 'r')\n","        df = json.load(fp)\n","        fp.close()\n","        text = df['item_7'] + df['item_7A']\n","        d,d2,d3 = give_all_three_occurences(text)\n","        d.to_csv(store_path+'word_count_'+i[:-5]+'.csv')\n","        d2.to_csv(store_path+'bigram_count_'+i[:-5]+'.csv')\n","        d3.to_csv(store_path+'trigram_count_'+i[:-5]+'.csv')\n","    except:\n","        files_that_dont_have_item_7A.append(i)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fx5vd1ax1XL6","outputId":"60437a54-8106-4815-e865-d24b43b1a8d9"},"outputs":[{"data":{"text/plain":["['10K_1342936_20151231_0001342936-16-000057.json',\n"," '10K_1342936_20161231_0001342936-17-000016.json',\n"," '10K_1342936_20171231_0001342936-18-000018.json',\n"," '10K_1342936_20181231_0001342936-19-000004.json',\n"," '10K_1342936_20191231_0001342936-20-000011.json',\n"," '10K_1342936_20201231_0001376474-21-000115.json',\n"," '10K_869531_20131231_0001127855-17-000067.json',\n"," '10K_869531_20141231_0001127855-17-000191.json',\n"," '10K_869531_20151231_0001127855-17-000195.json',\n"," '10K_869531_20161231_0001127855-17-000252.json',\n"," '10K_869531_20171231_0001127855-18-000049.json',\n"," '10K_869531_20181231_0001654954-19-003723.json']"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["files_that_dont_have_item_7A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eqdBbQy1XL6"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"NLP word_count_Pipeline.ipynb","provenance":[{"file_id":"155S_bb3viIoL0wAwkIyr1r8XQu4ARwA9","timestamp":1622880096687}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}